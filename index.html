<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Детектор синтетических изображений</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.21.0/dist/tf.min.js"></script>
  <script
    src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-tflite@0.0.1-alpha.8/dist/tf-tflite.min.js"
    onload="console.log('tf-tflite.min.js loaded successfully')"
    onerror="console.error('Failed to load tf-tflite.min.js')"
  ></script>
  <style>
    body { font-family: Arial, sans-serif; text-align: center; padding: 20px; }
    #preview { max-width: 300px; margin: 20px; }
    #result { color: #333; font-size: 1.2em; }
  </style>
</head>
<body>
  <h1>Детектор синтетических изображений</h1>
  <input type="file" id="imageInput" accept="image/*">
  <br>
  <img id="preview" src="" alt="Предпросмотр">
  <p id="result">Загрузите изображение для анализа</p>

  <script>
    const input = document.getElementById('imageInput');
    const preview = document.getElementById('preview');
    const result = document.getElementById('result');
    let model = null;
    let isModelLoaded = false;

    // Загрузка TFLite модели
    async function loadModel() {
      try {
        // Проверка наличия tflite
        if (typeof tflite === 'undefined') {
          throw new Error('Библиотека tfjs-tflite не загружена. Проверьте подключение скрипта.');
        }
        console.log('Loading TFLite model...');
        const tfliteModel = await tflite.loadTFLiteModel('/models/detector.tflite');
        model = tfliteModel;
        isModelLoaded = true;
        result.textContent = 'Модель загружена. Выберите изображение для анализа.';
        console.log('Модель TFLite успешно загружена');
      } catch (error) {
        result.textContent = 'Ошибка загрузки модели: ' + error.message;
        console.error('Ошибка загрузки модели:', error);
      }
    }

    // Предобработка изображения
    async function preprocessImage(image) {
      const canvas = document.createElement('canvas');
      canvas.width = 224;
      canvas.height = 224;
      const ctx = canvas.getContext('2d');
      ctx.drawImage(image, 0, 0, 224, 224);
      
      // Получение пиксельных данных
      const imageData = ctx.getImageData(0, 0, 224, 224).data;
      
      // Создание массива для NCHW: [1, 3, 224, 224]
      const input = new Float32Array(1 * 3 * 224 * 224);
      for (let y = 0; y < 224; y++) {
        for (let x = 0; x < 224; x++) {
          const idx = (y * 224 + x) * 4; // Индекс в imageData
          const r = (imageData[idx] / 255.0 - 0.485) / 0.229;     // R
          const g = (imageData[idx + 1] / 255.0 - 0.456) / 0.224; // G
          const b = (imageData[idx + 2] / 255.0 - 0.406) / 0.225; // B
          // Проверка на NaN или бесконечности
          if (isNaN(r) || isNaN(g) || isNaN(b) || !isFinite(r) || !isFinite(g) || !isFinite(b)) {
            throw new Error(`Invalid input values at pixel (${x}, ${y}): R=${r}, G=${g}, B=${b}`);
          }
          // Помещаем в NCHW: [0, c, y, x]
          input[0 * 3 * 224 * 224 + 0 * 224 * 224 + y * 224 + x] = r; // R канал
          input[0 * 3 * 224 * 224 + 1 * 224 * 224 + y * 224 + x] = g; // G канал
          input[0 * 3 * 224 * 224 + 2 * 224 * 224 + y * 224 + x] = b; // B канал
        }
      }
      const tensor = tf.tensor4d(input, [1, 3, 224, 224]);
      // Отладочный вывод
      console.log('Tensor shape:', tensor.shape);
      console.log('Tensor min:', tensor.min().dataSync()[0]);
      console.log('Tensor max:', tensor.max().dataSync()[0]);
      console.log('Sample values:', input.slice(0, 10));
      return tensor;
    }

    // Классификация изображения
    async function classifyImage(input) {
      if (!isModelLoaded || !model) {
        throw new Error('Модель ещё не загружена. Пожалуйста, подождите.');
      }
      console.log('Starting model prediction...');
      const output = await model.predict(input);
      console.log('Prediction completed:', output);
      const probabilities = output.dataSync();
      input.dispose(); // Освобождение памяти
      return probabilities[1]; // Вероятность класса FAKE
    }

    // Обработка загрузки изображения
    input.addEventListener('change', async (e) => {
      const file = e.target.files[0];
      if (!file) return;

      // Предпросмотр
      preview.src = URL.createObjectURL(file);
      preview.onload = async () => {
        if (!isModelLoaded) {
          result.textContent = 'Модель ещё загружается. Пожалуйста, подождите...';
          return;
        }
        result.textContent = 'Анализ...';
        try {
          const input = await preprocessImage(preview);
          const probability = await classifyImage(input);
          result.textContent = `Вероятность синтетического изображения: ${(probability * 100).toFixed(2)}%`;
        } catch (error) {
          result.textContent = 'Ошибка анализа: ' + error.message;
          console.error('Ошибка анализа:', error);
        }
      };
    });

    // Проверка загрузки WebAssembly
    console.log('Checking WebAssembly support...');
    if (typeof WebAssembly === 'undefined') {
      result.textContent = 'Ошибка: WebAssembly не поддерживается в этом браузере.';
      console.error('WebAssembly не поддерживается');
    } else {
      console.log('WebAssembly поддерживается');
      loadModel();
    }
  </script>
</body>
</html>